{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Credit Risk Classification\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview of the Analysis\n",
    "### Purpose\n",
    "* Explain the purpose of the analysis.\n",
    "\n",
    "### About the data\n",
    "* Explain what financial information the data was on, and what you needed to predict.\n",
    "* Provide basic information about the variables you were trying to predict (e.g., `value_counts`).\n",
    "\n",
    "\n",
    "### Methods used\n",
    "The following models form the `sklearn` library are evaluated:\n",
    "* `LogisticRegression` with original data (Model 1) and scaled data (Model 2)\n",
    "* `SVC` with scaled data (Model 3)\n",
    "* `tree` with scaled data (Model 4)\n",
    "* `RandomForest` with scaled data (Model 5)\n",
    "* `KNeighborsClassifier` with scaled data (Model 6)\n",
    "\n",
    "Note that PCA is not used as the number of features (dimensions) is reasonable and we do not expect any significant improvement by using Principal Components.\n",
    "\n",
    "### Stages\n",
    "We prepare the data for all the models in the next sections by performing the following steps:\n",
    "* Import all necessary modules (there are no imports within the other code blocks)\n",
    "* Load the data from the CSV file into a pandas DataFrame\n",
    "* Split the data between the training and test sets using `train_test_split` from `sklearn`\n",
    "\n",
    "For each of the models, we then perform the following steps\n",
    "* Scaling (optional)\n",
    "* Fitting (i.e. train the model with the training set)\n",
    "* Predictions (i.e. use the test set )\n",
    "* Describe the stages of the machine learning process you went through as part of this analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignore all warnings\n",
    "from warnings import simplefilter\n",
    "simplefilter(action='ignore')\n",
    "\n",
    "# Import dependencies\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Import the models from SKLearn (Model 1 through Model 6)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Local module\n",
    "from ml_classification import model_performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loan_size</th>\n",
       "      <th>interest_rate</th>\n",
       "      <th>borrower_income</th>\n",
       "      <th>debt_to_income</th>\n",
       "      <th>num_of_accounts</th>\n",
       "      <th>derogatory_marks</th>\n",
       "      <th>total_debt</th>\n",
       "      <th>loan_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10700.0</td>\n",
       "      <td>7.672</td>\n",
       "      <td>52800</td>\n",
       "      <td>0.431818</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>22800</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8400.0</td>\n",
       "      <td>6.692</td>\n",
       "      <td>43600</td>\n",
       "      <td>0.311927</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>13600</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9000.0</td>\n",
       "      <td>6.963</td>\n",
       "      <td>46100</td>\n",
       "      <td>0.349241</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>16100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10700.0</td>\n",
       "      <td>7.664</td>\n",
       "      <td>52700</td>\n",
       "      <td>0.430740</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>22700</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10800.0</td>\n",
       "      <td>7.698</td>\n",
       "      <td>53000</td>\n",
       "      <td>0.433962</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>23000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   loan_size  interest_rate  borrower_income  debt_to_income  num_of_accounts  \\\n",
       "0    10700.0          7.672            52800        0.431818                5   \n",
       "1     8400.0          6.692            43600        0.311927                3   \n",
       "2     9000.0          6.963            46100        0.349241                3   \n",
       "3    10700.0          7.664            52700        0.430740                5   \n",
       "4    10800.0          7.698            53000        0.433962                5   \n",
       "\n",
       "   derogatory_marks  total_debt  loan_status  \n",
       "0                 1       22800            0  \n",
       "1                 0       13600            0  \n",
       "2                 0       16100            0  \n",
       "3                 1       22700            0  \n",
       "4                 1       23000            0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the CSV file from the Resources folder into a Pandas DataFrame\n",
    "csv = Path('Resources/lending_data.csv')\n",
    "df = pd.read_csv(csv)\n",
    "\n",
    "# Review the DataFrame\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 77536 entries, 0 to 77535\n",
      "Data columns (total 8 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   loan_size         77536 non-null  float64\n",
      " 1   interest_rate     77536 non-null  float64\n",
      " 2   borrower_income   77536 non-null  int64  \n",
      " 3   debt_to_income    77536 non-null  float64\n",
      " 4   num_of_accounts   77536 non-null  int64  \n",
      " 5   derogatory_marks  77536 non-null  int64  \n",
      " 6   total_debt        77536 non-null  int64  \n",
      " 7   loan_status       77536 non-null  int64  \n",
      "dtypes: float64(3), int64(5)\n",
      "memory usage: 4.7 MB\n"
     ]
    }
   ],
   "source": [
    "# Review the DataFrame information\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Healthy (0)      75036\n",
       "High Risk (1)     2500\n",
       "Name: loan_status, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Review the \"loan_status\" information\n",
    "loan_status_df = df['loan_status'].value_counts()\n",
    "loan_status_df.index = ['Healthy (0)', 'High Risk (1)']\n",
    "display(loan_status_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data between Training and Test sets\n",
    "We create the labels set (`y`) from the “loan_status” column, and then create the features (`X`) DataFrame from the remaining columns. We then split the data into training and testing datasets by using `train_test_split`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the data into labels and features\n",
    "# Separate the y variable, the labels\n",
    "y = df['loan_status']\n",
    "\n",
    "# Separate the X variable, the features\n",
    "X = df.drop(columns='loan_status')\n",
    "\n",
    "# Split the data using train_test_split\n",
    "# Assign a random_state of 1 to the function\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,random_state=1,stratify=y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Model 1: Logistic Regression Model with the Original Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting\n",
    "Logistic regression model, using the training data (`X_train` and `y_train`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Score: 0.9914878250103177\n",
      "Testing Data Score: 0.9924164259182832\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the Logistic Regression model\n",
    "# Assign a random_state parameter of 1 to the model\n",
    "model_1 = LogisticRegression(solver='lbfgs', random_state=1, max_iter=100)\n",
    "\n",
    "# Fit the model using training data\n",
    "model_1 = model_1.fit(X_train, y_train)\n",
    "\n",
    "# Score the model\n",
    "print(f\"Training Data Score: {model_1.score(X_train, y_train)}\")\n",
    "print(f\"Testing Data Score: {model_1.score(X_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "Predictions vs Actual classification:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prediction</th>\n",
       "      <th>Actual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>36831</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75818</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36563</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13237</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43292</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Prediction  Actual\n",
       "36831           0       0\n",
       "75818           0       1\n",
       "36563           0       0\n",
       "13237           0       0\n",
       "43292           0       0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a prediction using the testing data\n",
    "print('---')\n",
    "print(\"Predictions vs Actual classification:\")\n",
    "predictions_1 = model_1.predict(X_test)\n",
    "classification_df = pd.DataFrame({'Prediction': predictions_1, \"Actual\": y_test})\n",
    "classification_df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "          Predicted 0  Predicted 1\n",
      "Actual 0        18679           80\n",
      "Actual 1           67          558\n",
      "---\n",
      "Accuracy Score : 0.9924164259182832\n",
      "---\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     18759\n",
      "           1       0.87      0.89      0.88       625\n",
      "\n",
      "    accuracy                           0.99     19384\n",
      "   macro avg       0.94      0.94      0.94     19384\n",
      "weighted avg       0.99      0.99      0.99     19384\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_performance(y_test, predictions_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusions for Model 1\n",
    "#### Observations\n",
    "- The precision for Class 0 is excellent (only 67 mistakes over more than 18k data points)\n",
    "- In other word, the ratio of false negatives over true positive is very small\n",
    "- The precision and recall for Class 1 is not as good (around 88%)\n",
    "- In other word, this model has a (very) small tendency to produce false positives (Type I error)\n",
    "\n",
    "#### Recommendations\n",
    "**Question:** How well does the logistic regression model predict both the `0` (healthy loan) and `1` (high-risk loan) labels?\n",
    "\n",
    "A value of 0 in the “loan_status” column means that the loan is healthy. A value of 1 means that the loan has a high risk of defaulting. A Type I error therefore means that a loan can be predicted as \"healthy\" when it is in fact \"risky.\"\n",
    "\n",
    "This is not in the favour of the creditor and a more conservative model (perhaps with a higher tendency for Type II errors but that creates fewer Type I errors) may be preferred. The model still shows very good performance and can be recommeded for the application but getting the Class 1 precision and recall closer to 95% could be preferrable for creditors who want to avoid exposing themselves to more risk than expected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Model 2: Logistic Regression Model with the Scaled Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data scaling (`X` only)\n",
    "The scaled data are saved in two variables: `X_train_scaled` and `X_test_scaled`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating StandardScaler instance\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fitting Standard Scaller\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Scaling data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting, Predictions, and Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "          Predicted 0  Predicted 1\n",
      "Actual 0        18669           90\n",
      "Actual 1           12          613\n",
      "---\n",
      "Accuracy Score : 0.9947379281881964\n",
      "---\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     18759\n",
      "           1       0.87      0.98      0.92       625\n",
      "\n",
      "    accuracy                           0.99     19384\n",
      "   macro avg       0.94      0.99      0.96     19384\n",
      "weighted avg       1.00      0.99      0.99     19384\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the Logistic Regression model\n",
    "# Assign a random_state parameter of 1 to the model\n",
    "model_2 = LogisticRegression(solver='lbfgs', random_state=1, max_iter=100)\n",
    "\n",
    "# Fit the model using training data\n",
    "model_2 = model_2.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make a prediction using the testing data\n",
    "predictions_2 = model_2.predict(X_test_scaled)\n",
    "\n",
    "# Model performance\n",
    "model_performance(y_test, predictions_2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Model 3: SVM with the Scaled Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.995\n",
      "Confusion Matrix:\n",
      "          Predicted 0  Predicted 1\n",
      "Actual 0        18669           90\n",
      "Actual 1           12          613\n",
      "---\n",
      "Accuracy Score : 0.9947379281881964\n",
      "---\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     18759\n",
      "           1       0.87      0.98      0.92       625\n",
      "\n",
      "    accuracy                           0.99     19384\n",
      "   macro avg       0.94      0.99      0.96     19384\n",
      "weighted avg       1.00      0.99      0.99     19384\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a support vector machine linear classifer, and fit it to the training data\n",
    "model_3 = SVC(kernel='linear')\n",
    "model_3.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Print the model score by using the test data\n",
    "print(f\"Test accuracy: {model_3.score(X_test_scaled, y_test):.3f}\")\n",
    "\n",
    "# Calculate the classification report\n",
    "predictions_3 = model_3.predict(X_test_scaled)\n",
    "\n",
    "# Model performance\n",
    "model_performance(y_test, predictions_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Model 4: Decision Tree with the Scaled Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "          Predicted 0  Predicted 1\n",
      "Actual 0        18668           91\n",
      "Actual 1            6          619\n",
      "---\n",
      "Accuracy Score : 0.9949958728848535\n",
      "---\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     18759\n",
      "           1       0.87      0.99      0.93       625\n",
      "\n",
      "    accuracy                           0.99     19384\n",
      "   macro avg       0.94      0.99      0.96     19384\n",
      "weighted avg       1.00      0.99      1.00     19384\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Creating the decision tree classifier instance\n",
    "model_4 = DecisionTreeClassifier(max_depth=5)\n",
    "\n",
    "# Fitting the model\n",
    "model_4 = model_4.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Making predictions using the testing data\n",
    "predictions_4 = model_4.predict(X_test_scaled)\n",
    "\n",
    "# Model performance\n",
    "model_performance(y_test, predictions_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Model 5: Random Forest with the Scaled Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "          Predicted 0  Predicted 1\n",
      "Actual 0        18680           79\n",
      "Actual 1           72          553\n",
      "---\n",
      "Accuracy Score : 0.9922100701609575\n",
      "---\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     18759\n",
      "           1       0.88      0.88      0.88       625\n",
      "\n",
      "    accuracy                           0.99     19384\n",
      "   macro avg       0.94      0.94      0.94     19384\n",
      "weighted avg       0.99      0.99      0.99     19384\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a random forest classifier\n",
    "model_5 = RandomForestClassifier(n_estimators=500, random_state=1)\n",
    "\n",
    "# Fitting the model\n",
    "model_5 = model_5.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Making predictions\n",
    "predictions_5 = model_5.predict(X_test_scaled)\n",
    "\n",
    "# Model performance\n",
    "model_performance(y_test, predictions_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Model 6: K-nearest neighbours with the Scaled Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "          Predicted 0  Predicted 1\n",
      "Actual 0        18681           78\n",
      "Actual 1           73          552\n",
      "---\n",
      "Accuracy Score : 0.9922100701609575\n",
      "---\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     18759\n",
      "           1       0.88      0.88      0.88       625\n",
      "\n",
      "    accuracy                           0.99     19384\n",
      "   macro avg       0.94      0.94      0.94     19384\n",
      "weighted avg       0.99      0.99      0.99     19384\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the model\n",
    "model_6 = KNeighborsClassifier(n_neighbors=4)\n",
    "\n",
    "# Train the model\n",
    "model_6.fit(X_train_scaled,y_train)\n",
    "\n",
    "# Create predictions\n",
    "predictions_6 = model_6.predict(X_test_scaled)\n",
    "\n",
    "# Model performance\n",
    "model_performance(y_test, predictions_6)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
